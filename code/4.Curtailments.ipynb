{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb4d49b",
   "metadata": {},
   "source": [
    "# Delta Water Unavailability Methodology Module 4: Curtailment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f260a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script calls the outputs of the Analysis script to summarize appropriate curtailments in the Sacramento-San Joaquin\n",
    "# Delta Waterhsed based on the results of the water unavailability analysis\n",
    "# Absent any active curtailment regulation, results are for informational purposes only and have no regulatory effect\n",
    "# Further documentation is available on the Delta Water Unavailability Methodology website:\n",
    "# https://www.waterboards.ca.gov/waterrights/water_issues/programs/drought/drought_tools_methods/delta_method.html\n",
    "\n",
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if required input files are present\n",
    "def check_required_outputs(folder_path, files_to_notebooks):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Required folder 'intermediate-outputs' does not exist. Please run the Supply, Demand, and Analysis notebooks first.\")\n",
    "        return False\n",
    "\n",
    "    missing_instructions = []\n",
    "    for file, notebook in files_to_notebooks.items():\n",
    "        if not os.path.exists(os.path.join(folder_path, file)):\n",
    "            missing_instructions.append(f\"{file} (Please run {notebook})\")\n",
    "\n",
    "    if missing_instructions:\n",
    "        missing_str = \"\\n\".join(missing_instructions)\n",
    "        print(f\"The following required files are missing:\\n{missing_str}\")\n",
    "        return False\n",
    "\n",
    "    print(\"All required intermediate outputs are present. Proceeding with analysis.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38dad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the intermediate outputs generated by previous scripts are present\n",
    "files_to_notebooks = {\n",
    "    'Demands_Period_POD.csv': 'Demand.ipynb',\n",
    "    'Supply_Period_Total.csv': 'Supply.ipynb',\n",
    "    'Headwater_Calculations.csv': 'Analysis.ipynb',\n",
    "    'Analysis_Results.csv': 'Analysis.ipynb',\n",
    "}\n",
    "\n",
    "if not check_required_outputs('./intermediate-outputs', files_to_notebooks):\n",
    "    display(Markdown(\"**Execution stopped. Please generate the required intermediate outputs before proceeding.**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datsets defining water rights, where they divert, and their demands\n",
    "water_rights = pd.read_csv('../user-inputs/WaterRights.csv')\n",
    "pods = pd.read_csv('../user-inputs/PODs.csv')\n",
    "demands_dataset = pd.read_csv('./intermediate-outputs/Demands_Period_POD.csv')\n",
    "\n",
    "# Import the results of the headwater and watershed-scale water unavailability analyses\n",
    "supply_period_total = pd.read_csv('./intermediate-outputs/Supply_Period_Total.csv')\n",
    "hwa_outputs = pd.read_csv('./intermediate-outputs/Headwater_Calculations.csv', index_col=0)\n",
    "analysis_dataset = pd.read_csv('./intermediate-outputs/Analysis_Results.csv', header=1, usecols = ['APPL_ID','WATERSHED','SUBWATERSHED', 'PRIORITY_DATE_CUSTOM', 'LEGAL_DELTA', 'HEADWATER', 'WATER_UNAVAILABLE_HEADWATER', 'WATER_UNAVAILABLE_WATERSHED', 'DEMAND_MET_WATERSHED_TOTAL', 'DEMAND_UNMET_WATERSHED_TOTAL', 'DEMAND_UNMET_HEADWATER_TOTAL'], dtype={'PRIORITY_DATE_CUSTOM':'string', 'WATER_UNAVAILABLE_HEADWATER':'bool', 'WATER_UNAVAILABLE_WATERSHED':'bool', 'WATER_UNAVAILABLE_EITHER':'bool'})\n",
    "# Import the same file again but keep the hierarchical columns\n",
    "analysis_dataset_heir = pd.read_csv('./intermediate-outputs/Analysis_Results.csv', header = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab results for the final record in the Analysis Results\n",
    "# These represent conditions after water unavailability is analyzed for the most junior right in the watershed\n",
    "supply_headwater_acct = analysis_dataset_heir.xs('SUPPLY_HEADWATER_ACCT', axis = 1, level = 0).iloc[-1]\n",
    "demand_headwater = analysis_dataset_heir.xs('DEMAND_HEADWATER', axis = 1, level = 0).iloc[-1]\n",
    "supply_watershed_acct = analysis_dataset_heir.xs('SUPPLY_WATERSHED_ACCT', axis = 1, level = 0).iloc[-1]\n",
    "demand_watershed = analysis_dataset_heir.xs('DEMAND_WATERSHED', axis = 1, level = 0).iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80656bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize imported Headwater Calculations for easier processing\n",
    "hwa_outputs = hwa_outputs.transpose()\n",
    "hwa_outputs = hwa_outputs.rename_axis('SUBWATERSHED').reset_index()\n",
    "hwa_outputs['SUPPLY_PERIOD_FINAL']=hwa_outputs['SUPPLY_PERIOD_FINAL'].astype(float)\n",
    "hwa_outputs['SUPPLY_PERIOD_TOTAL']=hwa_outputs['SUPPLY_PERIOD_TOTAL'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c33b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common lists of subwatersheds\n",
    "subwatersheds = ['Sacramento Bend', 'Stony', 'Cache', 'Upper Feather', 'Yuba', 'Bear', 'Upper American', 'Putah', \n",
    "                 'Upper Sacramento Valley', 'Sacramento Valley Floor', 'Chowchilla', 'Upper San Joaquin', 'Fresno',\n",
    "                 'Merced', 'Tuolumne', 'Stanislaus', 'Calaveras', 'Mokelumne', 'Cosumnes', 'San Joaquin Valley Floor']\n",
    "headwater_subwatershed = ['Sacramento Bend', 'Stony', 'Cache', 'Upper Feather', 'Yuba', 'Bear', 'Upper American', 'Putah', \n",
    "                 'Chowchilla', 'Upper San Joaquin', 'Fresno', 'Merced', 'Tuolumne', 'Stanislaus', 'Calaveras', 'Mokelumne',\n",
    "                'Cosumnes']\n",
    "summary_subwatersheds = ['Sacramento Bend', 'Stony', 'Cache', 'Upper Feather', 'Yuba', 'Bear', 'Upper American', 'Putah', \n",
    "                 'Upper Sacramento Valley', 'Sacramento Valley Floor', 'Chowchilla', 'Upper San Joaquin', 'Fresno',\n",
    "                 'Merced', 'Tuolumne', 'Stanislaus', 'Calaveras', 'Mokelumne', 'Cosumnes', 'San Joaquin Valley Floor',\n",
    "                'TOTAL']\n",
    "sacramento_subwatersheds = ['Sacramento Bend', 'Upper Sacramento Valley', 'Stony', 'Cache', 'Upper Feather',\n",
    "                            'Yuba', 'Bear', 'Upper American', 'Sacramento Valley Floor', 'Putah']\n",
    "sanjoaquin_subwatersheds = ['Chowchilla', 'Upper San Joaquin', 'Fresno', 'Merced', 'Tuolumne', \n",
    "                            'Stanislaus', 'Calaveras', 'Mokelumne', 'Cosumnes', 'San Joaquin Valley Floor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f99318",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create the Curtailment dataset by taking the Water Rights dataset (each row representing one water right or claim)\n",
    "and assign attributes explaining where each diverts\n",
    "'''\n",
    "\n",
    "# From the Water Rights dataset, take the list of rights and each's Primary Owner, Water Right Type, and Priority Date\n",
    "selected_columns = ['APPL_ID', 'PRIMARY_OWNER_NAME', 'WATER_RIGHT_TYPE_CUSTOM', 'PRIORITY_DATE_CUSTOM']\n",
    "water_rights = water_rights.dropna()\n",
    "curtailment_dataset = water_rights[selected_columns].copy()\n",
    "\n",
    "# Creating mappings for the PODs dataset\n",
    "pods_first_occurrence = pods.drop_duplicates(subset='APPL_ID')\n",
    "pods_mapping = pods_first_occurrence.set_index('APPL_ID')[['WATERSHED', 'SUBWATERSHED', 'LEGAL_DELTA']].to_dict('index')\n",
    "\n",
    "# Creating mappings for the Analysis dataset\n",
    "analysis_mapping = analysis_dataset.groupby('APPL_ID').agg({\n",
    "    'WATERSHED': lambda x: 'Both' if x.nunique() > 1 else x.iloc[0],# Indicate if demands exist in Both Sacramento and San Joaquin watersheds\n",
    "    'SUBWATERSHED': lambda x: 'Multiple' if x.nunique() > 1 else x.iloc[0],# Indicate if demands exist in Multiple subwatersheds\n",
    "    'LEGAL_DELTA': lambda x: 'Partial' if x.nunique() > 1 else x.iloc[0],# Indicate if demands exist Partial(ly) in the Legal Delta\n",
    "    'HEADWATER': lambda x: 'Partial' if x.nunique() > 1 else x.iloc[0]# Indicate if demands exist Partial(ly) in a Headwater subwatershed\n",
    "}).to_dict('index')\n",
    "\n",
    "def process_curtailment_row(row):\n",
    "    appl_id = row['APPL_ID']\n",
    "    priority_date = row['PRIORITY_DATE_CUSTOM']\n",
    "    # Information on Riparian-priority claims is only found in the PODs dataset\n",
    "    if priority_date == 'Riparian':\n",
    "        pods_row = pods_mapping.get(appl_id, {'WATERSHED': 'Unknown', 'SUBWATERSHED': 'Unknown', 'LEGAL_DELTA': 'Unknown'})\n",
    "        watershed, subwatershed, legal_delta = pods_row['WATERSHED'], pods_row['SUBWATERSHED'], pods_row['LEGAL_DELTA']\n",
    "        headwater = False if subwatershed in ['Upper Sacramento Valley', 'Sacramento Valley Floor', 'San Joaquin Valley Floor'] else True\n",
    "    # Information on all other claims and rights was already assembled in the Analysis dataset\n",
    "    else:\n",
    "        analysis_row = analysis_mapping.get(appl_id, {'WATERSHED': 'Unknown', 'SUBWATERSHED': 'Unknown', 'LEGAL_DELTA': 'Unknown', 'HEADWATER': 'Unknown'})\n",
    "        watershed, subwatershed, legal_delta, headwater = analysis_row['WATERSHED'], analysis_row['SUBWATERSHED'], analysis_row['LEGAL_DELTA'], analysis_row['HEADWATER']\n",
    "\n",
    "    return watershed, subwatershed, legal_delta, headwater\n",
    "\n",
    "curtailment_dataset[['WATERSHED', 'SUBWATERSHED', 'LEGAL_DELTA', 'HEADWATER']] = curtailment_dataset.apply(\n",
    "    lambda row: process_curtailment_row(row), axis=1, result_type='expand'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, determine Unavailability at the Headwater scale\n",
    "'''\n",
    "# Map each SUBWATERSHED to its corresponding SUPPLY_PERIOD_TOTAL to avoid repeated DataFrame lookups\n",
    "supply_period_totals = hwa_outputs.groupby('SUBWATERSHED')['SUPPLY_PERIOD_TOTAL'].first().to_dict()\n",
    "# Map each APPL_ID to a boolean indicating overall headwater unavailability status\n",
    "water_unavailable_headwater = analysis_dataset.groupby('APPL_ID')['WATER_UNAVAILABLE_HEADWATER'].all().to_dict()\n",
    "\n",
    "def determine_unavailability_headwater(row):\n",
    "    # Unavailability to Riparian claims is unique\n",
    "    if row['PRIORITY_DATE_CUSTOM'] == 'Riparian' and not row['LEGAL_DELTA'] and row['HEADWATER']:\n",
    "        # Check unavailability for Riparian rights in the specified SUBWATERSHED\n",
    "        supply_period_final_value = supply_period_totals.get(row['SUBWATERSHED'], 0)\n",
    "        return supply_period_final_value == 0\n",
    "    elif water_unavailable_headwater.get(row['APPL_ID'], False):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "curtailment_dataset['UNAVAILABILITY_HEADWATER'] = curtailment_dataset.apply(\n",
    "    determine_unavailability_headwater, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea38be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, determine Unavailability at the Watershed scale\n",
    "'''\n",
    "\n",
    "# Aggregated 'SUPPLY_PERIOD_FINAL' totals for defined subwatershed groups.\n",
    "aggregated_supply_period_final = {\n",
    "    'sacramento': hwa_outputs.loc[hwa_outputs['SUBWATERSHED'].isin(sacramento_subwatersheds), 'SUPPLY_PERIOD_FINAL'].sum(),\n",
    "    'sanjoaquin': hwa_outputs.loc[hwa_outputs['SUBWATERSHED'].isin(sanjoaquin_subwatersheds), 'SUPPLY_PERIOD_FINAL'].sum(),\n",
    "    'total': hwa_outputs['SUPPLY_PERIOD_FINAL'].sum(),\n",
    "}\n",
    "# Individual 'SUPPLY_PERIOD_FINAL' values for each subwatershed outside headwater\n",
    "individual_supply_period_final = {\n",
    "    'Upper Sacramento Valley': hwa_outputs.loc[hwa_outputs['SUBWATERSHED'].isin(['Sacramento Bend', 'Upper Sacramento Valley']), 'SUPPLY_PERIOD_FINAL'].sum(),\n",
    "    'Sacramento Valley Floor': hwa_outputs.loc[hwa_outputs['SUBWATERSHED'].isin(['Sacramento Bend', 'Upper Sacramento Valley', 'Stony', 'Cache', 'Upper Feather', \n",
    "                                                                                 'Yuba', 'Bear', 'Upper American', 'Sacramento Valley Floor']), 'SUPPLY_PERIOD_FINAL'].sum(),\n",
    "    'San Joaquin Valley Floor': hwa_outputs.loc[hwa_outputs['SUBWATERSHED'].isin(['Upper San Joaquin', 'Fresno', 'Chowchilla', 'Merced', \n",
    "                                                                                  'Tuolomne', 'San Joaquin Valley Floor']), 'SUPPLY_PERIOD_FINAL'].sum(),\n",
    "}\n",
    "\n",
    "# Maps each APPL_ID to a boolean indicating if water is unavailable at the headwater.\n",
    "water_unavailable_headwater = analysis_dataset.groupby('APPL_ID')['WATER_UNAVAILABLE_HEADWATER'].all().to_dict()\n",
    "\n",
    "# Maps each APPL_ID to a boolean indicating if water is unavailable at the watershed for non-Riparian rights.\n",
    "non_riparian_unavailability = analysis_dataset[analysis_dataset['PRIORITY_DATE_CUSTOM'] != 'Riparian'\n",
    "                                              ].groupby('APPL_ID')['WATER_UNAVAILABLE_WATERSHED'].all().to_dict()\n",
    "\n",
    "# Function to determine watershed-scale unavailability\n",
    "def determine_unavailability_watershed(row):\n",
    "    if water_unavailable_headwater.get(row['APPL_ID'], False):\n",
    "        return False\n",
    "    # Unavailability to Riparian claims is unique\n",
    "    if row['PRIORITY_DATE_CUSTOM'] == 'Riparian':\n",
    "        # Legal Delta riparian unavailability is based on total supplies from upstream subwatersheds\n",
    "        if row['LEGAL_DELTA']:\n",
    "            # Check unavailability for Riparian rights within the Legal Delta\n",
    "            if row['WATER_RIGHT_TYPE_CUSTOM'] == 'Statement of Div and Use (Riparian)':\n",
    "                if row['WATERSHED'] == 'Sacramento':\n",
    "                    return aggregated_supply_period_final['sacramento'] == 0\n",
    "                elif row['WATERSHED'] == 'San Joaquin':\n",
    "                    return aggregated_supply_period_final['sanjoaquin'] == 0\n",
    "            else:\n",
    "                return aggregated_supply_period_final['total'] == 0\n",
    "        elif not row['LEGAL_DELTA'] and row['HEADWATER']:\n",
    "            subwatershed_supply = hwa_outputs.loc[\n",
    "                hwa_outputs['SUBWATERSHED'] == row['SUBWATERSHED'], 'SUPPLY_PERIOD_TOTAL'].sum()\n",
    "            return subwatershed_supply == 0\n",
    "        elif not row['LEGAL_DELTA'] and not row['HEADWATER']:\n",
    "            return individual_supply_period_final.get(row['SUBWATERSHED'], 0) == 0\n",
    "    else:\n",
    "        return non_riparian_unavailability.get(row['APPL_ID'], False)\n",
    "\n",
    "    return False\n",
    "\n",
    "# Apply the function\n",
    "curtailment_dataset['UNAVAILABILITY_WATERSHED'] = curtailment_dataset.apply(determine_unavailability_watershed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, determine if Water Unavailable at Either the Headwater or Watershed scale \n",
    "'''\n",
    "\n",
    "curtailment_dataset['UNAVAILABILITY_EITHER'] = curtailment_dataset.apply(\n",
    "    lambda row: row['UNAVAILABILITY_HEADWATER'] or row['UNAVAILABILITY_WATERSHED'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5322a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, determine a Curtailment Status based on water unavailability\n",
    "'''\n",
    "''' Pending Water Right Types are unlawful claims that are never authorized to divert\n",
    "    Curtailment Status is based on water unavailabity at either the headwater or watershed scale\n",
    "    Periodically during the emergency regulation, the Deputy Director for Water Rights exercised discretion\n",
    "    to base curtailments only on the watershed-scale analysis (UNAVAILABILITY_WATERSHED)\n",
    "'''\n",
    "\n",
    "curtailment_dataset['CURTAILMENT_STATUS'] = curtailment_dataset.apply(\n",
    "    lambda row: 'Not Authorized to Divert' if row['PRIORITY_DATE_CUSTOM'] == 'Pending' else ('Curtailed' if row['UNAVAILABILITY_EITHER'] else 'Not Curtailed'), axis=1)\n",
    "\n",
    "## TO DO: build additional functionality based on other aspects of water rights\n",
    "## e.g., under the emergency regulation Cannabis Registrations were Not Authorized to Divert during the forebearance season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef901bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, calculate a total Demand (Direct + Storage for the user-specified period)\n",
    "'''\n",
    "demands_sum = demands_dataset.groupby('APPL_ID').agg({\n",
    "    'DIRECT_PERIOD_POD': 'sum',\n",
    "    'STORAGE_PERIOD_POD': 'sum'\n",
    "}).reset_index()\n",
    "demands_sum['TOTAL_DEMAND'] = demands_sum['DIRECT_PERIOD_POD'] + demands_sum['STORAGE_PERIOD_POD']\n",
    "\n",
    "curtailment_dataset = curtailment_dataset.merge(demands_sum[['APPL_ID', 'TOTAL_DEMAND']].rename(columns={'TOTAL_DEMAND': 'DEMAND_CURTAILMENT'}), on='APPL_ID', how='left')\n",
    "curtailment_dataset['DEMAND_CURTAILMENT'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, calculate a total Demand Met\n",
    "'''\n",
    "demand_met_total = analysis_dataset.groupby('APPL_ID')['DEMAND_MET_WATERSHED_TOTAL'].sum().reset_index()\n",
    "\n",
    "# Merges curtailment records with aggregated demand met totals by APPL_ID for precise DEMAND_MET_CURTAILMENT calculation.\n",
    "temp_df = curtailment_dataset.merge(demand_met_total, on='APPL_ID', how='left')\n",
    "\n",
    "curtailment_dataset['DEMAND_MET_CURTAILMENT'] = np.where(\n",
    "    curtailment_dataset['PRIORITY_DATE_CUSTOM'] == \"Riparian\",\n",
    "    np.where(curtailment_dataset['UNAVAILABILITY_EITHER'], 0, curtailment_dataset['DEMAND_CURTAILMENT']),\n",
    "    temp_df['DEMAND_MET_WATERSHED_TOTAL'].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, determine if there is Partial Unavailability\n",
    "(i.e., some water is available but not 100% of demand can be met)\n",
    "'''\n",
    "\n",
    "curtailment_dataset['UNAVAILABILITY_PARTIAL'] = curtailment_dataset.apply(\n",
    "    lambda row: row['DEMAND_CURTAILMENT'] > 0 and row['DEMAND_MET_CURTAILMENT'] < row['DEMAND_CURTAILMENT'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65995e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the Curtailment Data\n",
    "curtailment_dataset.to_csv('./output-data/Curtailment_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe399fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Develop a Curtailment Details Summary table for each of the 20 Subwatersheds, the Legal Delta, and a Total value\n",
    "'''\n",
    "\n",
    "# Function to calculate various summary values\n",
    "def calculate_summary_values(subwatershed):\n",
    "    headwater_priority_date = \"\"\n",
    "    watershed_priority_date = \"\"\n",
    "    demand_unmet_headwater = 0\n",
    "    demand_unmet_watershed = 0\n",
    "    excess_supply_headwater = 0\n",
    "    excess_supply_watershed = 0\n",
    "    num_curtailments = 0\n",
    "    demand_curtailment = 0\n",
    "    \n",
    "    # Filter Curtailment dataset for the current subwatershed\n",
    "    subwatershed_curtailment = curtailment_dataset.loc[curtailment_dataset['SUBWATERSHED'] == subwatershed]\n",
    "    \n",
    "    # Determine Headwater Priority Date of First Curtailment\n",
    "    # (the most senior right or claim where Water Unavailable in Headwater is true)\n",
    "    if subwatershed in headwater_subwatershed:\n",
    "        sacramento_total_supply = hwa_outputs[hwa_outputs['SUBWATERSHED'].isin(sacramento_subwatersheds)]['SUPPLY_PERIOD_TOTAL'].sum()\n",
    "        if sacramento_total_supply == 0:\n",
    "            headwater_priority_date = 'Riparian'\n",
    "        else:\n",
    "            # Check if there is any unavailability at the headwater scale\n",
    "            headwater_filtered_df = analysis_dataset.loc[(analysis_dataset['SUBWATERSHED'] == subwatershed) & \n",
    "                                                           (analysis_dataset['WATER_UNAVAILABLE_HEADWATER'] == True)]\n",
    "            if not headwater_filtered_df.empty:\n",
    "                headwater_priority_date = headwater_filtered_df['PRIORITY_DATE_CUSTOM'].iloc[0]\n",
    "            else:\n",
    "                # If there are no curtailments at the headwater scale, show \"-\"\n",
    "                headwater_priority_date = '-'\n",
    "    \n",
    "    # For headwater subwatersheds, show \"N/A\"\n",
    "    elif subwatershed not in headwater_subwatershed:\n",
    "        headwater_priority_date = 'N/A'\n",
    "\n",
    "    # Determine Watershed Priority Date of First Curtailment\n",
    "    if subwatershed == 'TOTAL':\n",
    "        watershed_priority_date = 'N/A'\n",
    "    else:\n",
    "        watershed_filtered_df = analysis_dataset.loc[(analysis_dataset['SUBWATERSHED'] == subwatershed) & \n",
    "                                                     (analysis_dataset['WATER_UNAVAILABLE_WATERSHED'] == True)]\n",
    "        if not watershed_filtered_df.empty:\n",
    "            watershed_priority_date = watershed_filtered_df['PRIORITY_DATE_CUSTOM'].iloc[0]\n",
    "        else:\n",
    "            watershed_priority_date = '-'\n",
    "\n",
    "    # Calculate Demand Unmet in Headwater Analysis\n",
    "    if subwatershed in subwatersheds:\n",
    "        demand_unmet_headwater = analysis_dataset.loc[(analysis_dataset['SUBWATERSHED'] == subwatershed) & \n",
    "                                                      (analysis_dataset['LEGAL_DELTA'] == False)]['DEMAND_UNMET_HEADWATER_TOTAL'].sum()\n",
    "    elif subwatershed == 'Total':\n",
    "        demand_unmet_headwater = analysis_dataset['DEMAND_UNMET_HEADWATER_TOTAL'].sum()\n",
    "    \n",
    "    # Calculate Demand Unmet in Watershed Analysis\n",
    "    if subwatershed in subwatersheds:\n",
    "        demand_unmet_watershed = analysis_dataset.loc[(analysis_dataset['SUBWATERSHED'] == subwatershed) & \n",
    "                                                      (analysis_dataset['LEGAL_DELTA'] == False)]['DEMAND_UNMET_WATERSHED_TOTAL'].sum()\n",
    "    elif subwatershed == 'Total':\n",
    "        demand_unmet_watershed = analysis_dataset['DEMAND_UNMET_WATERSHED_TOTAL'].sum()\n",
    "\n",
    "    # Calculate Excess Supply in Headwater Analysis\n",
    "    if subwatershed in headwater_subwatershed:\n",
    "        excess_supply_headwater = max(0, (supply_headwater_acct[subwatershed] - demand_headwater[subwatershed]))\n",
    "    elif subwatershed == 'Total':\n",
    "        excess_supply_headwater = max(0, (supply_headwater_acct.sum() - demand_headwater.sum()))\n",
    "    else:\n",
    "        excess_supply_headwater = 'N/A'\n",
    "    \n",
    "    # Calculate Excess Supply in Watershed Analysis\n",
    "    if subwatershed in subwatersheds:\n",
    "        excess_supply_watershed = max(0, (supply_watershed_acct[subwatershed] - demand_watershed[subwatershed]))\n",
    "    elif subwatershed == 'Total':\n",
    "        excess_supply_watershed = max(0, (supply_watershed_acct.sum() - demand_watershed.sum()))\n",
    "\n",
    "    # Calculate Number of Curtailments\n",
    "    if subwatershed in subwatersheds:\n",
    "        num_curtailments = len(subwatershed_curtailment[(subwatershed_curtailment['CURTAILMENT_STATUS'] == \"Curtailed\") & \n",
    "                                                         (subwatershed_curtailment['LEGAL_DELTA'] == False)])\n",
    "    elif subwatershed == 'Total':\n",
    "        num_curtailments = len(subwatershed_curtailment[subwatershed_curtailment['CURTAILMENT_STATUS'] == \"Curtailed\"])\n",
    "    \n",
    "    # Calculate Demand of Curtailed Rights\n",
    "    if subwatershed in subwatersheds:\n",
    "        demand_curtailment = subwatershed_curtailment[(subwatershed_curtailment['CURTAILMENT_STATUS'] == \"Curtailed\") & \n",
    "                                                      (subwatershed_curtailment['LEGAL_DELTA'] == False)]['DEMAND_CURTAILMENT'].sum()\n",
    "    elif subwatershed == 'Total':\n",
    "        demand_curtailment = subwatershed_curtailment[(subwatershed_curtailment['CURTAILMENT_STATUS'] == \"Curtailed\")]['DEMAND_CURTAILMENT'].sum()\n",
    "    \n",
    "    return [subwatershed, headwater_priority_date, watershed_priority_date, demand_unmet_headwater, \n",
    "            demand_unmet_watershed, excess_supply_headwater, excess_supply_watershed, \n",
    "            num_curtailments, demand_curtailment]\n",
    "\n",
    "summary_list = []    \n",
    "\n",
    "# Execute the function for all subwatersheds\n",
    "for subwatershed in summary_subwatersheds:\n",
    "    summary_dict = calculate_summary_values(subwatershed)\n",
    "    summary_list.append(summary_dict)\n",
    "\n",
    "# Convert the list of summary values to a dataframe\n",
    "curtailment_summary = pd.DataFrame(summary_list, columns=['Subwatershed', \n",
    "                                           'Headwater Priority Date of First Curtailment',\n",
    "                                           'Watershed Priority Date of First Curtailment',\n",
    "                                           'Demand Unmet in Headwater Analysis', \n",
    "                                           'Demand Unmet in Watershed Analysis',\n",
    "                                           'Excess Supply in Headwater Analysis',\n",
    "                                           'Excess Supply in Watershed Analysis',\n",
    "                                           'Number of Curtailments',\n",
    "                                           'Demand of Curtailed Rights'])\n",
    "\n",
    "# Convert specific columns to integer for display\n",
    "int_columns = ['Demand Unmet in Headwater Analysis', \n",
    "               'Demand Unmet in Watershed Analysis',\n",
    "               'Excess Supply in Headwater Analysis',\n",
    "               'Excess Supply in Watershed Analysis',\n",
    "               'Number of Curtailments',\n",
    "               'Demand of Curtailed Rights']\n",
    "\n",
    "for col in int_columns:\n",
    "    # Check if the column is not of a string type to avoid errors\n",
    "    if curtailment_summary[col].dtype != 'object':\n",
    "        curtailment_summary[col] = np.ceil(curtailment_summary[col].fillna(0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and export the Curtailment Details Summary table\n",
    "display(curtailment_summary)\n",
    "curtailment_summary.to_csv('./output-data/Curtailment_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262bf0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Develop a Project Coordinated Operations Agreement (COA) Rights Summary table\n",
    "In recognition of the COAâ€™s provisions for sharing limited Project supplies,\n",
    "these rights were only curtailed if water was unavailable to all of them in the watershed-scale analysis\n",
    "(consistent with curtailment implementation since the 6/27/2022 Methodology update)\n",
    "'''\n",
    "\n",
    "# Filter the DataFrame to include only rows where 'PRIORITY_DATE_CUSTOM' is 'Project'\n",
    "project_coa_rights_df = curtailment_dataset[curtailment_dataset['PRIORITY_DATE_CUSTOM'] == 'Project']\n",
    "\n",
    "# Extract the list of Application IDs for 'Project' rights\n",
    "project_coa_rights = project_coa_rights_df['APPL_ID'].unique().tolist()\n",
    "\n",
    "# Look up Unavailability (at Either Headwater or Watershed scale) for each right\n",
    "project_coa_curtailment = curtailment_dataset[curtailment_dataset['APPL_ID'].isin(project_coa_rights)].copy()\n",
    "water_unavailable_to_all = project_coa_curtailment['UNAVAILABILITY_EITHER'].all()\n",
    "    \n",
    "# Set the CURTAILMENT_STATUS for all Project COA rights\n",
    "project_coa_curtailment.loc[:, 'CURTAILMENT_STATUS'] = np.where(\n",
    "    project_coa_curtailment['UNAVAILABILITY_EITHER'], \"Curtailed\", \"Not Curtailed\"\n",
    ")\n",
    "\n",
    "# Create the Project COA Rights Summary Table\n",
    "project_coa_summary = project_coa_curtailment[['APPL_ID', 'UNAVAILABILITY_EITHER', 'CURTAILMENT_STATUS']]\n",
    "\n",
    "# Display the Project COA Rights Summary Table and Water Unavailable to All status\n",
    "print(\"Project COA Rights Summary:\")\n",
    "display(project_coa_summary)\n",
    "print(\"\\nWater Unavailable to All Project COA Rights:\", water_unavailable_to_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the Project COA Rights Summary table\n",
    "project_coa_summary.to_csv('./output-data/Project_Rights_Summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
