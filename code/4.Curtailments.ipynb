{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb4d49b",
   "metadata": {},
   "source": [
    "# Delta Water Unavailability Methodology Module 4: Curtailment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f260a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script calls the outputs of the Analysis script to summarize appropriate curtailments in the Sacramento-San Joaquin\n",
    "# Delta Waterhsed based on the results of the water unavailability analysis\n",
    "# Absent any active curtailment regulation, results are for informational purposes only and have no regulatory effect\n",
    "# Further documentation is available on the Delta Water Unavailability Methodology website:\n",
    "# https://www.waterboards.ca.gov/waterrights/water_issues/programs/drought/drought_tools_methods/delta_method.html\n",
    "\n",
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if required input files are present\n",
    "def check_required_outputs(folder_path, files_to_notebooks):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Required folder 'intermediate-outputs' does not exist. Please run the Supply, Demand, and Analysis notebooks first.\")\n",
    "        return False\n",
    "\n",
    "    missing_instructions = []\n",
    "    for file, notebook in files_to_notebooks.items():\n",
    "        if not os.path.exists(os.path.join(folder_path, file)):\n",
    "            missing_instructions.append(f\"{file} (Please run {notebook})\")\n",
    "\n",
    "    if missing_instructions:\n",
    "        missing_str = \"\\n\".join(missing_instructions)\n",
    "        print(f\"The following required files are missing:\\n{missing_str}\")\n",
    "        return False\n",
    "\n",
    "    print(\"All required intermediate outputs are present. Proceeding with analysis.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38dad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the intermediate outputs generated by previous scripts are present\n",
    "files_to_notebooks = {\n",
    "    'Demands_Period_POD.csv': 'Demand.ipynb',\n",
    "    'Supply_Period_Total.csv': 'Supply.ipynb',\n",
    "    'Headwater_Calculations.csv': 'Analysis.ipynb',\n",
    "    'Analysis_Results.csv': 'Analysis.ipynb',\n",
    "}\n",
    "\n",
    "if not check_required_outputs('./intermediate-outputs', files_to_notebooks):\n",
    "    display(Markdown(\"**Execution stopped. Please generate the required intermediate outputs before proceeding.**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datsets defining water rights, where they divert, and their demands\n",
    "water_rights = pd.read_csv('../user-inputs/WaterRights.csv')\n",
    "pods = pd.read_csv('../user-inputs/PODs.csv')\n",
    "demands_dataset = pd.read_csv('./intermediate-outputs/Demands_Period_POD.csv')\n",
    "\n",
    "# Import the results of the headwater and watershed-scale water unavailability analyses\n",
    "supply_period_total = pd.read_csv('./intermediate-outputs/Supply_Period_Total.csv')\n",
    "hwa_outputs = pd.read_csv('./intermediate-outputs/Headwater_Calculations.csv', index_col=0)\n",
    "analysis_dataset = pd.read_csv('./intermediate-outputs/Analysis_Results.csv', header=1, usecols = ['APPL_ID','WATERSHED','SUBWATERSHED', 'PRIORITY_DATE_CUSTOM', 'LEGAL_DELTA', 'HEADWATER', 'WATER_UNAVAILABLE_HEADWATER', 'WATER_UNAVAILABLE_WATERSHED', 'DEMAND_MET_WATERSHED_TOTAL', 'DEMAND_UNMET_WATERSHED_TOTAL', 'DEMAND_UNMET_HEADWATER_TOTAL'], dtype={'PRIORITY_DATE_CUSTOM':'string', 'WATER_UNAVAILABLE_HEADWATER':'bool', 'WATER_UNAVAILABLE_WATERSHED':'bool', 'WATER_UNAVAILABLE_EITHER':'bool'})\n",
    "# Import the same file again but keep the hierarchical columns\n",
    "analysis_dataset_heir = pd.read_csv('./intermediate-outputs/Analysis_Results.csv', header = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab results for the final record in the Analysis Results\n",
    "# These represent conditions after water unavailability is analyzed for the most junior right in the watershed\n",
    "supply_headwater_acct = analysis_dataset_heir.xs('SUPPLY_HEADWATER_ACCT', axis = 1, level = 0).iloc[-1]\n",
    "demand_headwater = analysis_dataset_heir.xs('DEMAND_HEADWATER', axis = 1, level = 0).iloc[-1]\n",
    "supply_watershed_acct = analysis_dataset_heir.xs('SUPPLY_WATERSHED_ACCT', axis = 1, level = 0).iloc[-1]\n",
    "demand_watershed = analysis_dataset_heir.xs('DEMAND_WATERSHED', axis = 1, level = 0).iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80656bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize imported Headwater Calculations for easier processing\n",
    "hwa_outputs = hwa_outputs.transpose()\n",
    "hwa_outputs = hwa_outputs.rename_axis('SUBWATERSHED').reset_index()\n",
    "hwa_outputs['SUPPLY_PERIOD_FINAL']=hwa_outputs['SUPPLY_PERIOD_FINAL'].astype(float)\n",
    "hwa_outputs['SUPPLY_PERIOD_TOTAL']=hwa_outputs['SUPPLY_PERIOD_TOTAL'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c33b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common lists of subwatersheds\n",
    "subwatersheds = ['Sacramento Bend', 'Stony', 'Cache', 'Upper Feather', 'Yuba', 'Bear', 'Upper American', 'Putah', \n",
    "                 'Upper Sacramento Valley', 'Sacramento Valley Floor', 'Chowchilla', 'Upper San Joaquin', 'Fresno',\n",
    "                 'Merced', 'Tuolumne', 'Stanislaus', 'Calaveras', 'Mokelumne', 'Cosumnes', 'San Joaquin Valley Floor']\n",
    "headwater_subwatershed = ['Sacramento Bend', 'Stony', 'Cache', 'Upper Feather', 'Yuba', 'Bear', 'Upper American', 'Putah', \n",
    "                 'Chowchilla', 'Upper San Joaquin', 'Fresno', 'Merced', 'Tuolumne', 'Stanislaus', 'Calaveras', 'Mokelumne',\n",
    "                'Cosumnes']\n",
    "summary_subwatersheds = ['Sacramento Bend', 'Stony', 'Cache', 'Upper Feather', 'Yuba', 'Bear', 'Upper American', 'Putah', \n",
    "                 'Upper Sacramento Valley', 'Sacramento Valley Floor', 'Chowchilla', 'Upper San Joaquin', 'Fresno',\n",
    "                 'Merced', 'Tuolumne', 'Stanislaus', 'Calaveras', 'Mokelumne', 'Cosumnes', 'San Joaquin Valley Floor',\n",
    "                'TOTAL']\n",
    "sacramento_subwatersheds = ['Sacramento Bend', 'Upper Sacramento Valley', 'Stony', 'Cache', 'Upper Feather',\n",
    "                            'Yuba', 'Bear', 'Upper American', 'Sacramento Valley Floor', 'Putah']\n",
    "sanjoaquin_subwatersheds = ['Chowchilla', 'Upper San Joaquin', 'Fresno', 'Merced', 'Tuolumne', \n",
    "                            'Stanislaus', 'Calaveras', 'Mokelumne', 'Cosumnes', 'San Joaquin Valley Floor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f99318",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create the Curtailment dataset by taking the Water Rights dataset (each row representing one water right or claim)\n",
    "and assign attributes explaining where each diverts\n",
    "'''\n",
    "\n",
    "# From the Water Rights dataset, take the list of rights and each's Primary Owner, Water Right Type, and Priority Date\n",
    "selected_columns = ['APPL_ID', 'PRIMARY_OWNER_NAME', 'WATER_RIGHT_TYPE_CUSTOM', 'PRIORITY_DATE_CUSTOM']\n",
    "water_rights = water_rights.dropna()\n",
    "curtailment_dataset = water_rights[selected_columns].copy()\n",
    "\n",
    "# Creating mappings for the PODs dataset\n",
    "pods_first_occurrence = pods.drop_duplicates(subset='APPL_ID')\n",
    "pods_mapping = pods_first_occurrence.set_index('APPL_ID')[['WATERSHED', 'SUBWATERSHED', 'LEGAL_DELTA']].to_dict('index')\n",
    "\n",
    "# Creating mappings for the Analysis dataset\n",
    "analysis_mapping = analysis_dataset.groupby('APPL_ID').agg({\n",
    "    'WATERSHED': lambda x: 'Both' if x.nunique() > 1 else x.iloc[0],# Indicate if demands exist in Both Sacramento and San Joaquin watersheds\n",
    "    'SUBWATERSHED': lambda x: 'Multiple' if x.nunique() > 1 else x.iloc[0],# Indicate if demands exist in Multiple subwatersheds\n",
    "    'LEGAL_DELTA': lambda x: 'Partial' if x.nunique() > 1 else x.iloc[0],# Indicate if demands exist Partial(ly) in the Legal Delta\n",
    "    'HEADWATER': lambda x: 'Partial' if x.nunique() > 1 else x.iloc[0]# Indicate if demands exist Partial(ly) in a Headwater subwatershed\n",
    "}).to_dict('index')\n",
    "\n",
    "def process_curtailment_row(row):\n",
    "    appl_id = row['APPL_ID']\n",
    "    priority_date = row['PRIORITY_DATE_CUSTOM']\n",
    "    # Information on Riparian-priority claims is only found in the PODs dataset\n",
    "    if priority_date == 'Riparian':\n",
    "        pods_row = pods_mapping.get(appl_id, {'WATERSHED': 'Unknown', 'SUBWATERSHED': 'Unknown', 'LEGAL_DELTA': 'Unknown'})\n",
    "        watershed, subwatershed, legal_delta = pods_row['WATERSHED'], pods_row['SUBWATERSHED'], pods_row['LEGAL_DELTA']\n",
    "        headwater = False if subwatershed in ['Upper Sacramento Valley', 'Sacramento Valley Floor', 'San Joaquin Valley Floor'] else True\n",
    "    # Information on all other claims and rights was already assembled in the Analysis dataset\n",
    "    else:\n",
    "        analysis_row = analysis_mapping.get(appl_id, {'WATERSHED': 'Unknown', 'SUBWATERSHED': 'Unknown', 'LEGAL_DELTA': 'Unknown', 'HEADWATER': 'Unknown'})\n",
    "        watershed, subwatershed, legal_delta, headwater = analysis_row['WATERSHED'], analysis_row['SUBWATERSHED'], analysis_row['LEGAL_DELTA'], analysis_row['HEADWATER']\n",
    "\n",
    "    return watershed, subwatershed, legal_delta, headwater\n",
    "\n",
    "curtailment_dataset[['WATERSHED', 'SUBWATERSHED', 'LEGAL_DELTA', 'HEADWATER']] = curtailment_dataset.apply(\n",
    "    lambda row: process_curtailment_row(row), axis=1, result_type='expand'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, determine Unavailability at the Headwater scale\n",
    "'''\n",
    "# Map each SUBWATERSHED to its corresponding SUPPLY_PERIOD_TOTAL to avoid repeated DataFrame lookups\n",
    "supply_period_totals = hwa_outputs.groupby('SUBWATERSHED')['SUPPLY_PERIOD_TOTAL'].first().to_dict()\n",
    "# Map each APPL_ID to a boolean indicating overall headwater unavailability status\n",
    "water_unavailable_headwater = analysis_dataset.groupby('APPL_ID')['WATER_UNAVAILABLE_HEADWATER'].all().to_dict()\n",
    "\n",
    "def determine_unavailability_headwater(row):\n",
    "    # Unavailability to Riparian claims is unique\n",
    "    if row['PRIORITY_DATE_CUSTOM'] == 'Riparian' and not row['LEGAL_DELTA'] and row['HEADWATER']:\n",
    "        # Check unavailability for Riparian rights in the specified SUBWATERSHED\n",
    "        supply_period_final_value = supply_period_totals.get(row['SUBWATERSHED'], 0)\n",
    "        return supply_period_final_value == 0\n",
    "    elif water_unavailable_headwater.get(row['APPL_ID'], False):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "curtailment_dataset['UNAVAILABILITY_HEADWATER'] = curtailment_dataset.apply(\n",
    "    determine_unavailability_headwater, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea38be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, determine Unavailability at the Watershed scale\n",
    "'''\n",
    "\n",
    "# Aggregated 'SUPPLY_PERIOD_FINAL' totals for defined subwatershed groups.\n",
    "aggregated_supply_period_final = {\n",
    "    'sacramento': hwa_outputs.loc[hwa_outputs['SUBWATERSHED'].isin(sacramento_subwatersheds), 'SUPPLY_PERIOD_FINAL'].sum(),\n",
    "    'sanjoaquin': hwa_outputs.loc[hwa_outputs['SUBWATERSHED'].isin(sanjoaquin_subwatersheds), 'SUPPLY_PERIOD_FINAL'].sum(),\n",
    "    'total': hwa_outputs['SUPPLY_PERIOD_FINAL'].sum(),\n",
    "}\n",
    "# Individual 'SUPPLY_PERIOD_FINAL' values for each subwatershed outside headwater\n",
    "individual_supply_period_final = {\n",
    "    'Upper Sacramento Valley': hwa_outputs.loc[hwa_outputs['SUBWATERSHED'].isin(['Sacramento Bend', 'Upper Sacramento Valley']), 'SUPPLY_PERIOD_FINAL'].sum(),\n",
    "    'Sacramento Valley Floor': hwa_outputs.loc[hwa_outputs['SUBWATERSHED'].isin(['Sacramento Bend', 'Upper Sacramento Valley', 'Stony', 'Cache', 'Upper Feather', \n",
    "                                                                                 'Yuba', 'Bear', 'Upper American', 'Sacramento Valley Floor']), 'SUPPLY_PERIOD_FINAL'].sum(),\n",
    "    'San Joaquin Valley Floor': hwa_outputs.loc[hwa_outputs['SUBWATERSHED'].isin(['Upper San Joaquin', 'Fresno', 'Chowchilla', 'Merced', \n",
    "                                                                                  'Tuolomne', 'San Joaquin Valley Floor']), 'SUPPLY_PERIOD_FINAL'].sum(),\n",
    "}\n",
    "\n",
    "# Maps each APPL_ID to a boolean indicating if water is unavailable at the headwater.\n",
    "water_unavailable_headwater = analysis_dataset.groupby('APPL_ID')['WATER_UNAVAILABLE_HEADWATER'].all().to_dict()\n",
    "\n",
    "# Maps each APPL_ID to a boolean indicating if water is unavailable at the watershed for non-Riparian rights.\n",
    "non_riparian_unavailability = analysis_dataset[analysis_dataset['PRIORITY_DATE_CUSTOM'] != 'Riparian'\n",
    "                                              ].groupby('APPL_ID')['WATER_UNAVAILABLE_WATERSHED'].all().to_dict()\n",
    "\n",
    "# Function to determine watershed-scale unavailability\n",
    "def determine_unavailability_watershed(row):\n",
    "    if water_unavailable_headwater.get(row['APPL_ID'], False):\n",
    "        return False\n",
    "    # Unavailability to Riparian claims is unique\n",
    "    if row['PRIORITY_DATE_CUSTOM'] == 'Riparian':\n",
    "        # Legal Delta riparian unavailability is based on total supplies from upstream subwatersheds\n",
    "        if row['LEGAL_DELTA']:\n",
    "            # Check unavailability for Riparian rights within the Legal Delta\n",
    "            if row['WATER_RIGHT_TYPE_CUSTOM'] == 'Statement of Div and Use (Riparian)':\n",
    "                if row['WATERSHED'] == 'Sacramento':\n",
    "                    return aggregated_supply_period_final['sacramento'] == 0\n",
    "                elif row['WATERSHED'] == 'San Joaquin':\n",
    "                    return aggregated_supply_period_final['sanjoaquin'] == 0\n",
    "            else:\n",
    "                return aggregated_supply_period_final['total'] == 0\n",
    "        elif not row['LEGAL_DELTA'] and row['HEADWATER']:\n",
    "            subwatershed_supply = hwa_outputs.loc[\n",
    "                hwa_outputs['SUBWATERSHED'] == row['SUBWATERSHED'], 'SUPPLY_PERIOD_TOTAL'].sum()\n",
    "            return subwatershed_supply == 0\n",
    "        elif not row['LEGAL_DELTA'] and not row['HEADWATER']:\n",
    "            return individual_supply_period_final.get(row['SUBWATERSHED'], 0) == 0\n",
    "    else:\n",
    "        return non_riparian_unavailability.get(row['APPL_ID'], False)\n",
    "\n",
    "    return False\n",
    "\n",
    "# Apply the function\n",
    "curtailment_dataset['UNAVAILABILITY_WATERSHED'] = curtailment_dataset.apply(determine_unavailability_watershed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, determine if Water Unavailable at Either the Headwater or Watershed scale \n",
    "'''\n",
    "\n",
    "curtailment_dataset['UNAVAILABILITY_EITHER'] = curtailment_dataset.apply(\n",
    "    lambda row: row['UNAVAILABILITY_HEADWATER'] or row['UNAVAILABILITY_WATERSHED'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5322a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, determine a Curtailment Status based on water unavailability\n",
    "'''\n",
    "''' Pending Water Right Types are unlawful claims that are never authorized to divert\n",
    "    Curtailment Status is based on water unavailabity at either the headwater or watershed scale\n",
    "    Periodically during the emergency regulation, the Deputy Director for Water Rights exercised discretion\n",
    "    to base curtailments only on the watershed-scale analysis (UNAVAILABILITY_WATERSHED)\n",
    "'''\n",
    "\n",
    "curtailment_dataset['CURTAILMENT_STATUS'] = curtailment_dataset.apply(\n",
    "    lambda row: 'Not Authorized to Divert' if row['PRIORITY_DATE_CUSTOM'] == 'Pending' else ('Curtailed' if row['UNAVAILABILITY_EITHER'] else 'Not Curtailed'), axis=1)\n",
    "\n",
    "## TO DO: build additional functionality based on other aspects of water rights\n",
    "## e.g., under the emergency regulation Cannabis Registrations were Not Authorized to Divert during the forebearance season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef901bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, calculate a total Demand (Direct + Storage for the user-specified period)\n",
    "'''\n",
    "demands_sum = demands_dataset.groupby('APPL_ID').agg({\n",
    "    'DIRECT_PERIOD_POD': 'sum',\n",
    "    'STORAGE_PERIOD_POD': 'sum'\n",
    "}).reset_index()\n",
    "demands_sum['TOTAL_DEMAND'] = demands_sum['DIRECT_PERIOD_POD'] + demands_sum['STORAGE_PERIOD_POD']\n",
    "\n",
    "curtailment_dataset = curtailment_dataset.merge(demands_sum[['APPL_ID', 'TOTAL_DEMAND']].rename(columns={'TOTAL_DEMAND': 'DEMAND_CURTAILMENT'}), on='APPL_ID', how='left')\n",
    "curtailment_dataset['DEMAND_CURTAILMENT'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, calculate a total Demand Met\n",
    "'''\n",
    "demand_met_total = analysis_dataset.groupby('APPL_ID')['DEMAND_MET_WATERSHED_TOTAL'].sum().reset_index()\n",
    "\n",
    "# Merges curtailment records with aggregated demand met totals by APPL_ID for precise DEMAND_MET_CURTAILMENT calculation.\n",
    "temp_df = curtailment_dataset.merge(demand_met_total, on='APPL_ID', how='left')\n",
    "\n",
    "curtailment_dataset['DEMAND_MET_CURTAILMENT'] = np.where(\n",
    "    curtailment_dataset['PRIORITY_DATE_CUSTOM'] == \"Riparian\",\n",
    "    np.where(curtailment_dataset['UNAVAILABILITY_EITHER'], 0, curtailment_dataset['DEMAND_CURTAILMENT']),\n",
    "    temp_df['DEMAND_MET_WATERSHED_TOTAL'].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each right, determine if there is Partial Unavailability\n",
    "(i.e., some water is available but not 100% of demand can be met)\n",
    "'''\n",
    "\n",
    "curtailment_dataset['UNAVAILABILITY_PARTIAL'] = curtailment_dataset.apply(\n",
    "    lambda row: row['DEMAND_CURTAILMENT'] > 0 and row['DEMAND_MET_CURTAILMENT'] < row['DEMAND_CURTAILMENT'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65995e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the Curtailment Data\n",
    "curtailment_dataset.to_csv('./output-data/Curtailment_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe399fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Develop a Curtailment Details Summary table for each of the 20 Subwatersheds, the Legal Delta, and a Total value\n",
    "'''\n",
    "\n",
    "# Function to calculate various summary values\n",
    "def calculate_summary_values(subwatershed):\n",
    "    headwater_priority_date = \"\"\n",
    "    watershed_priority_date = \"\"\n",
    "    demand_unmet_headwater = 0\n",
    "    demand_unmet_watershed = 0\n",
    "    excess_supply_headwater = 0\n",
    "    excess_supply_watershed = 0\n",
    "    num_curtailments = 0\n",
    "    demand_curtailment = 0\n",
    "    \n",
    "    # Filter Curtailment dataset for the current subwatershed\n",
    "    subwatershed_curtailment = curtailment_dataset.loc[curtailment_dataset['SUBWATERSHED'] == subwatershed]\n",
    "    \n",
    "    # Determine Headwater Priority Date of First Curtailment\n",
    "    # (the most senior right or claim where Water Unavailable in Headwater is true)\n",
    "    if subwatershed in headwater_subwatershed:\n",
    "        sacramento_total_supply = hwa_outputs[hwa_outputs['SUBWATERSHED'].isin(sacramento_subwatersheds)]['SUPPLY_PERIOD_TOTAL'].sum()\n",
    "        if sacramento_total_supply == 0:\n",
    "            headwater_priority_date = 'Riparian'\n",
    "        else:\n",
    "            # Check if there is any unavailability at the headwater scale\n",
    "            headwater_filtered_df = analysis_dataset.loc[(analysis_dataset['SUBWATERSHED'] == subwatershed) & \n",
    "                                                           (analysis_dataset['WATER_UNAVAILABLE_HEADWATER'] == True)]\n",
    "            if not headwater_filtered_df.empty:\n",
    "                headwater_priority_date = headwater_filtered_df['PRIORITY_DATE_CUSTOM'].iloc[0]\n",
    "            else:\n",
    "                # If there are no curtailments at the headwater scale, show \"-\"\n",
    "                headwater_priority_date = '-'\n",
    "    \n",
    "    # For headwater subwatersheds, show \"N/A\"\n",
    "    elif subwatershed not in headwater_subwatershed:\n",
    "        headwater_priority_date = 'N/A'\n",
    "\n",
    "    # Determine Watershed Priority Date of First Curtailment\n",
    "    if subwatershed == 'TOTAL':\n",
    "        watershed_priority_date = 'N/A'\n",
    "    else:\n",
    "        watershed_filtered_df = analysis_dataset.loc[(analysis_dataset['SUBWATERSHED'] == subwatershed) & \n",
    "                                                     (analysis_dataset['WATER_UNAVAILABLE_WATERSHED'] == True)]\n",
    "        if not watershed_filtered_df.empty:\n",
    "            watershed_priority_date = watershed_filtered_df['PRIORITY_DATE_CUSTOM'].iloc[0]\n",
    "        else:\n",
    "            watershed_priority_date = '-'\n",
    "\n",
    "    # Calculate Demand Unmet in Headwater Analysis\n",
    "    if subwatershed in subwatersheds:\n",
    "        demand_unmet_headwater = analysis_dataset.loc[(analysis_dataset['SUBWATERSHED'] == subwatershed) & \n",
    "                                                      (analysis_dataset['LEGAL_DELTA'] == False)]['DEMAND_UNMET_HEADWATER_TOTAL'].sum()\n",
    "    elif subwatershed == 'Total':\n",
    "        demand_unmet_headwater = analysis_dataset['DEMAND_UNMET_HEADWATER_TOTAL'].sum()\n",
    "    \n",
    "    # Calculate Demand Unmet in Watershed Analysis\n",
    "    if subwatershed in subwatersheds:\n",
    "        demand_unmet_watershed = analysis_dataset.loc[(analysis_dataset['SUBWATERSHED'] == subwatershed) & \n",
    "                                                      (analysis_dataset['LEGAL_DELTA'] == False)]['DEMAND_UNMET_WATERSHED_TOTAL'].sum()\n",
    "    elif subwatershed == 'Total':\n",
    "        demand_unmet_watershed = analysis_dataset['DEMAND_UNMET_WATERSHED_TOTAL'].sum()\n",
    "\n",
    "    # Calculate Excess Supply in Headwater Analysis\n",
    "    if subwatershed in headwater_subwatershed:\n",
    "        excess_supply_headwater = max(0, (supply_headwater_acct[subwatershed] - demand_headwater[subwatershed]))\n",
    "    elif subwatershed == 'Total':\n",
    "        excess_supply_headwater = max(0, (supply_headwater_acct.sum() - demand_headwater.sum()))\n",
    "    else:\n",
    "        excess_supply_headwater = 'N/A'\n",
    "    \n",
    "    # Calculate Excess Supply in Watershed Analysis\n",
    "    if subwatershed in subwatersheds:\n",
    "        excess_supply_watershed = max(0, (supply_watershed_acct[subwatershed] - demand_watershed[subwatershed]))\n",
    "    elif subwatershed == 'Total':\n",
    "        excess_supply_watershed = max(0, (supply_watershed_acct.sum() - demand_watershed.sum()))\n",
    "\n",
    "    # Calculate Number of Curtailments\n",
    "    if subwatershed in subwatersheds:\n",
    "        num_curtailments = len(subwatershed_curtailment[(subwatershed_curtailment['CURTAILMENT_STATUS'] == \"Curtailed\") & \n",
    "                                                         (subwatershed_curtailment['LEGAL_DELTA'] == False)])\n",
    "    elif subwatershed == 'Total':\n",
    "        num_curtailments = len(subwatershed_curtailment[subwatershed_curtailment['CURTAILMENT_STATUS'] == \"Curtailed\"])\n",
    "    \n",
    "    # Calculate Demand of Curtailed Rights\n",
    "    if subwatershed in subwatersheds:\n",
    "        demand_curtailment = subwatershed_curtailment[(subwatershed_curtailment['CURTAILMENT_STATUS'] == \"Curtailed\") & \n",
    "                                                      (subwatershed_curtailment['LEGAL_DELTA'] == False)]['DEMAND_CURTAILMENT'].sum()\n",
    "    elif subwatershed == 'Total':\n",
    "        demand_curtailment = subwatershed_curtailment[(subwatershed_curtailment['CURTAILMENT_STATUS'] == \"Curtailed\")]['DEMAND_CURTAILMENT'].sum()\n",
    "    \n",
    "    return [subwatershed, headwater_priority_date, watershed_priority_date, demand_unmet_headwater, \n",
    "            demand_unmet_watershed, excess_supply_headwater, excess_supply_watershed, \n",
    "            num_curtailments, demand_curtailment]\n",
    "\n",
    "summary_list = []    \n",
    "\n",
    "# Execute the function for all subwatersheds\n",
    "for subwatershed in summary_subwatersheds:\n",
    "    summary_dict = calculate_summary_values(subwatershed)\n",
    "    summary_list.append(summary_dict)\n",
    "\n",
    "# Convert the list of summary values to a dataframe\n",
    "curtailment_summary = pd.DataFrame(summary_list, columns=['Subwatershed', \n",
    "                                           'Headwater Priority Date of First Curtailment',\n",
    "                                           'Watershed Priority Date of First Curtailment',\n",
    "                                           'Demand Unmet in Headwater Analysis', \n",
    "                                           'Demand Unmet in Watershed Analysis',\n",
    "                                           'Excess Supply in Headwater Analysis',\n",
    "                                           'Excess Supply in Watershed Analysis',\n",
    "                                           'Number of Curtailments',\n",
    "                                           'Demand of Curtailed Rights'])\n",
    "\n",
    "# Convert specific columns to integer for display\n",
    "int_columns = ['Demand Unmet in Headwater Analysis', \n",
    "               'Demand Unmet in Watershed Analysis',\n",
    "               'Excess Supply in Headwater Analysis',\n",
    "               'Excess Supply in Watershed Analysis',\n",
    "               'Number of Curtailments',\n",
    "               'Demand of Curtailed Rights']\n",
    "\n",
    "for col in int_columns:\n",
    "    # Check if the column is not of a string type to avoid errors\n",
    "    if curtailment_summary[col].dtype != 'object':\n",
    "        curtailment_summary[col] = np.ceil(curtailment_summary[col].fillna(0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and export the Curtailment Details Summary table\n",
    "display(curtailment_summary)\n",
    "curtailment_summary.to_csv('./output-data/Curtailment_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262bf0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Develop a Project Coordinated Operations Agreement (COA) Rights Summary table\n",
    "In recognition of the COA’s provisions for sharing limited Project supplies,\n",
    "these rights were only curtailed if water was unavailable to all of them in the watershed-scale analysis\n",
    "(consistent with curtailment implementation since the 6/27/2022 Methodology update)\n",
    "'''\n",
    "\n",
    "# Filter the DataFrame to include only rows where 'PRIORITY_DATE_CUSTOM' is 'Project'\n",
    "project_coa_rights_df = curtailment_dataset[curtailment_dataset['PRIORITY_DATE_CUSTOM'] == 'Project']\n",
    "\n",
    "# Extract the list of Application IDs for 'Project' rights\n",
    "project_coa_rights = project_coa_rights_df['APPL_ID'].unique().tolist()\n",
    "\n",
    "# Look up Unavailability (at Either Headwater or Watershed scale) for each right\n",
    "project_coa_curtailment = curtailment_dataset[curtailment_dataset['APPL_ID'].isin(project_coa_rights)].copy()\n",
    "water_unavailable_to_all = project_coa_curtailment['UNAVAILABILITY_EITHER'].all()\n",
    "    \n",
    "# Set the CURTAILMENT_STATUS for all Project COA rights\n",
    "project_coa_curtailment.loc[:, 'CURTAILMENT_STATUS'] = np.where(\n",
    "    project_coa_curtailment['UNAVAILABILITY_EITHER'], \"Curtailed\", \"Not Curtailed\"\n",
    ")\n",
    "\n",
    "# Create the Project COA Rights Summary Table\n",
    "project_coa_summary = project_coa_curtailment[['APPL_ID', 'UNAVAILABILITY_EITHER', 'CURTAILMENT_STATUS']]\n",
    "\n",
    "# Display the Project COA Rights Summary Table and Water Unavailable to All status\n",
    "print(\"Project COA Rights Summary:\")\n",
    "display(project_coa_summary)\n",
    "print(\"\\nWater Unavailable to All Project COA Rights:\", water_unavailable_to_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the Project COA Rights Summary table\n",
    "project_coa_summary.to_csv('./output-data/Project_Rights_Summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
