{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1700ef",
   "metadata": {},
   "source": [
    "# Delta Water Unavailability Methodology Module 1: Supply Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script takes user inputs and calls published supply datasets in the Sacramento-San Joaquin Delta Watershed\n",
    "# to prepare them for the water unavailability analysis.\n",
    "# Further documentation is available on the Delta Water Unavailability Methodology website:\n",
    "# https://www.waterboards.ca.gov/waterrights/water_issues/programs/drought/drought_tools_methods/delta_method.html\n",
    "\n",
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import calendar\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c0a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create output folders if they don't already exist\n",
    "def create_folder(folder_path):\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        \n",
    "        # If not, create the folder\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' already exists.\")\n",
    "\n",
    "# Create intermediate-outputs folder\n",
    "folder_path = './intermediate-outputs'\n",
    "create_folder(folder_path)\n",
    "\n",
    "# Create output-data folder\n",
    "folder_path = './output-data'\n",
    "create_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8060940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common lists of CNRFC sites and subwatersheds\n",
    "cnrfc_site = ['BDBC1', 'EPRC1', 'ORDC1', 'HLEC1', 'FOLC1', 'EDCC1', 'TCRC1', 'MLMC1', 'DCVC1', 'BKCC1', 'BHNC1',\n",
    "         'FRAC1', 'HIDC1', 'EXQC1', 'NDPC1', 'NMSC1', 'NHGC1', 'CMPC1', 'MHBC1', 'MPAC1', 'OWCC1', 'MEEC1']\n",
    "\n",
    "subwatershed = ['Sacramento Bend', 'Stony', 'Cache', 'Upper Feather', 'Yuba', 'Bear', 'Upper American', 'Putah', \n",
    "                 'Upper Sacramento Valley', 'Sacramento Valley Floor', 'Chowchilla', 'Upper San Joaquin', 'Fresno',\n",
    "                 'Merced', 'Tuolumne', 'Stanislaus', 'Calaveras', 'Mokelumne', 'Cosumnes', 'San Joaquin Valley Floor']\n",
    "\n",
    "# 13 of the subwatersheds correspond with single CNRFC sites\n",
    "match = [['Sacramento Bend', 'BDBC1'], ['Upper Feather', 'ORDC1'], ['Yuba', 'HLEC1'], ['Upper American', 'FOLC1'],\n",
    "         ['Upper San Joaquin', 'FRAC1'], ['Chowchilla', 'BHNC1'], ['Fresno', 'HIDC1'], ['Merced', 'EXQC1'],\n",
    "         ['Tuolumne', 'NDPC1'], ['Stanislaus', 'NMSC1'], ['Calaveras', 'NHGC1'], ['Mokelumne', 'CMPC1'], ['Cosumnes', 'MHBC1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d38c7",
   "metadata": {},
   "source": [
    "## A) Past Supply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd9172",
   "metadata": {},
   "source": [
    "#### Specify Start and End Dates for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to verify that the specified date is in the expected format\n",
    "def verify_user_date(prompt, min_date, max_date):\n",
    "    while True:\n",
    "        try:\n",
    "            date_input = input(prompt)\n",
    "            # Parse the date using dateutil\n",
    "            parsed_date = parse(date_input, dayfirst=False, yearfirst=False)\n",
    "            \n",
    "            # Remove time details\n",
    "            parsed_date = parsed_date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "            if parsed_date < min_date or parsed_date > max_date:\n",
    "                raise ValueError(f\"Date must be between {min_date.strftime('%m/%d/%Y')} and {max_date.strftime('%m/%d/%Y')}.\")\n",
    "            \n",
    "            # Display the parsed date for user confirmation\n",
    "            friendly_date = parsed_date.strftime('%B %d, %Y')\n",
    "            confirmation = input(f\"You've entered the date: {friendly_date}. Is this correct? (Y/N): \").strip().lower()\n",
    "            if confirmation in ['y', 'yes']:\n",
    "                return parsed_date\n",
    "            else:\n",
    "                print(\"Please re-enter the date.\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Invalid date entered: {e}. Please try again.\")\n",
    "\n",
    "\n",
    "# Define the earliest start date and the latest end date\n",
    "earliest_start_date = datetime.strptime(\"10/01/2012\", \"%m/%d/%Y\").replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "latest_end_date = datetime.now() + relativedelta(years=1)\n",
    "\n",
    "# Specify user input for start and end dates\n",
    "def get_dates_within_range():\n",
    "    start_date = verify_user_date(\"Enter your start date (MM/DD/YYYY): \", earliest_start_date, latest_end_date)\n",
    "    end_date = verify_user_date(\"Enter your end date (MM/DD/YYYY): \", earliest_start_date, latest_end_date)\n",
    "    \n",
    "    # Ensure start_date is before end_date\n",
    "    while start_date >= end_date:\n",
    "        print(\"The start date must be before the end date. Please enter both dates again.\")\n",
    "        start_date = verify_user_date(\"Enter your start date in the specified format(MM/DD/YYYY): \", earliest_start_date, latest_end_date)\n",
    "        end_date = verify_user_date(\"Enter your end date in the specified format (MM/DD/YYYY): \", earliest_start_date, latest_end_date)\n",
    "\n",
    "    return start_date, end_date\n",
    "\n",
    "start_date, end_date = get_dates_within_range()\n",
    "\n",
    "# Check if End date is in the past or future\n",
    "current_date = datetime.now()\n",
    "end_date_past = end_date if end_date < current_date else current_date - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c766a543",
   "metadata": {},
   "source": [
    "#### Specify Forecast Exceedance Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The single specified exceedance probability will be used to generate forecasts for all 20 subwatersheds\n",
    "\n",
    "# Determine the number of traces dynamically\n",
    "site_forecast = pd.read_csv('https://www.cnrfc.noaa.gov/csv/BDBC1_hefs_csv_daily.csv', header = None)\n",
    "num_traces = site_forecast.shape[1] - 1\n",
    "\n",
    "def get_valid_exceedance(num_traces):\n",
    "    # Calculate minimum and maximum exceedance values\n",
    "    min_excd = 1 / (num_traces + 1)\n",
    "    max_excd = 1 - min_excd\n",
    "\n",
    "    while True:  # Loop until valid input is received\n",
    "        try:\n",
    "            # Get user input for exceedance value\n",
    "            user_excd_input = input(\"Enter % Exceedance value: \\n\")\n",
    "            user_excd = float(user_excd_input.strip('%')) / 100\n",
    "\n",
    "            # Check if the exceedance value is within the allowed range or special cases\n",
    "            if min_excd <= user_excd <= max_excd or user_excd in [0.01, 0.99]:\n",
    "                return user_excd  # Return valid exceedance value\n",
    "            else:\n",
    "                print(f\"ERROR! Value is too narrow. Please enter an Exceedance value in the range of {min_excd * 100:.1f}% - {max_excd * 100:.1f}% (with the exception of 1% and 99% that will yield the min and max exceedance values, respectively.)\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a numeric value.\")\n",
    "\n",
    "user_excd = get_valid_exceedance(num_traces)\n",
    "\n",
    "## TO DO: add functionality for the user to specify exceedances for individual subwatersheds\n",
    "\n",
    "## TO DO: add functionality for the user to enter custom volumetric forecasts for any subwatershed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d2630",
   "metadata": {},
   "source": [
    "#### Store Start and End Date, and Exceedance Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a35623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily store date and exceedance variables, to be called in the 2.Demand.ipynb script\n",
    "%store start_date\n",
    "%store end_date\n",
    "\n",
    "%store user_excd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e5145",
   "metadata": {},
   "source": [
    "### i) Import CNRFC past supply data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c934a9a",
   "metadata": {},
   "source": [
    "#### Links depend on the water year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a660b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine water year from an input date\n",
    "def wateryear(date):\n",
    "    temp = date.strftime('%Y')\n",
    "\n",
    "    if int(date.strftime('%m')) >= 10:\n",
    "        water_year = int(temp) + 1\n",
    "    else:\n",
    "        water_year = int(temp)\n",
    "    return water_year  \n",
    "\n",
    "# Call function for specified Start and End Dates\n",
    "start_year = wateryear(start_date)\n",
    "end_year = wateryear(end_date_past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88b601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNRFC past supply data is published by water year; all available data from each relevant year is downloaded into a list\n",
    "\n",
    "# Initialize a list to store data for each site for each year\n",
    "data_list = []\n",
    "# Initialize a variable to store dates (assuming they are the same for all sites)\n",
    "dates = []\n",
    "\n",
    "# Create local variables of Start and End Date years that will be altered \n",
    "a = start_year\n",
    "b = end_year\n",
    "\n",
    "# Nested loop to gather data from multiple water years and multiple sites\n",
    "# Loop through water year(s) in date range\n",
    "while a <= b:\n",
    "    # Temporary list to store data for the current year\n",
    "    year_data = []\n",
    "    \n",
    "    # Loop through 22 CNRFC sites\n",
    "    for x in range (22):\n",
    "        # Import CSV of past data for a single site from CNRFC\n",
    "        df = pd.read_csv('https://www.cnrfc.noaa.gov/ensembleProductTabularCsv.php?id='+cnrfc_site[x]+'&prodID=9&year='+str(a))\n",
    "        \n",
    "        # Copy past 'observed' (estimated unimpaired) values into a list\n",
    "        year_data.append(df['Raw Daily Observation (TAF)'].tolist())\n",
    "    \n",
    "    # Store dates separetly to append later\n",
    "    dates.extend(df['Date'].tolist())\n",
    "    \n",
    "    # Once all sites for a water year are processed, append the water year data to the main list\n",
    "    data_list.extend(zip(*year_data))  # Transpose and extend the main list\n",
    "    \n",
    "    # Advance one year\n",
    "    a += 1\n",
    "\n",
    "# Convert the list of lists into a DataFrame\n",
    "past_supply = pd.DataFrame(data_list, columns=cnrfc_site)\n",
    "\n",
    "# Add a date column\n",
    "past_supply.insert(0, 'Date', dates)\n",
    "past_supply = past_supply.reset_index(drop=True)\n",
    "\n",
    "#display(past_supply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4f0a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "past_supply['Date'] = pd.to_datetime(past_supply['Date'])\n",
    "\n",
    "# Pull data from the dataframe for only the specified date range\n",
    "select = (past_supply['Date'] >= start_date) & (past_supply['Date'] <= end_date_past)\n",
    "past_supply_range = past_supply.loc[select]\n",
    "past_supply_range = past_supply_range.reset_index(drop=True)\n",
    "\n",
    "#display(past_supply_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595a97a",
   "metadata": {},
   "source": [
    "### ii) Sum Past Supply for specified period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c1c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Date column first\n",
    "past_supply_range = past_supply_range.iloc[: , 1:]\n",
    "\n",
    "# Sum past supply for the specified date range, inclusive of start and end dates\n",
    "# CNRFC past values are in TAF, convert to AF for analysis\n",
    "supply_past_period = past_supply_range.sum()*1000\n",
    "\n",
    "# The above will be zero if the Start Date is in the future\n",
    "supply_past_period=pd.DataFrame(supply_past_period)\n",
    "supply_past_period.reset_index(inplace=True)\n",
    "supply_past_period.columns =['CNRFC Site', 'SUPPLY_PAST_PERIOD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b02cf",
   "metadata": {},
   "source": [
    "## B. Forecasted Supply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde95860",
   "metadata": {},
   "source": [
    "### i) Import CNRFC Forecasted Supply data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67554f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store forecast trace data\n",
    "all_traces = []\n",
    "\n",
    "# Nested loop to gather data from multiple CNRFC sites and forecast traces\n",
    "# Loop through 22 CNRC sites\n",
    "for site_index in range (22):\n",
    "    # Import CSV of forecast data for a single site from CNRFC\n",
    "    site_forecast = pd.read_csv(f'https://www.cnrfc.noaa.gov/csv/{cnrfc_site[site_index]}_hefs_csv_daily.csv', header = None)\n",
    "    site_forecast.columns = site_forecast.iloc[0]\n",
    "    site_forecast = site_forecast.iloc[2:]\n",
    "    \n",
    "    # Remove time components from forecast data (each row is 1 day)\n",
    "    site_forecast['GMT'] = site_forecast['GMT'].apply(lambda x: parse(x).replace(hour=0, minute=0, second=0, microsecond=0))\n",
    "    site_forecast = site_forecast[(site_forecast['GMT'] >= start_date)&(site_forecast['GMT'] <= end_date)]\n",
    "    site_forecast = site_forecast.reset_index(drop=True)\n",
    "\n",
    "    # Initialize a list to store traces for the current site\n",
    "    site_traces = []\n",
    "    \n",
    "    # Loop through forecast traces, calculating a total forecasted supply for the specified dates\n",
    "    for trace_index in range (num_traces):\n",
    "        total = site_forecast.iloc[:, trace_index + 1].astype(float).sum()\n",
    "        \n",
    "        # CNRFC forecast traces are in TCFS, convert totals to AF\n",
    "        trace = total*60*60*24/43560*1000\n",
    "        \n",
    "        # Store the trace in the site_traces list\n",
    "        site_traces.append(trace)\n",
    "    \n",
    "    # Add the site traces to the all_traces list\n",
    "    all_traces.append(site_traces)\n",
    "\n",
    "# Convert the all_traces list to a dataframe\n",
    "Trace = pd.DataFrame(all_traces, columns=[f'Trace{i+1}' for i in range(num_traces)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd021e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Label dataframe to match Methodology spreadsheet\n",
    "Trace['CNRFC Site'] = cnrfc_site\n",
    "Trace.set_index(\"CNRFC Site\", inplace=True)\n",
    "\n",
    "#display(Trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191fec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO: Add functionality to intake DWR's Bulletin 120 water supply forecasts:\n",
    "## https://cdec.water.ca.gov/reportapp/javareports?name=SRWSI.pdf\n",
    "## https://cdec.water.ca.gov/reportapp/javareports?name=SJWSI.pdf\n",
    "## https://cdec.water.ca.gov/reportapp/javareports?name=B120DIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61003343",
   "metadata": {},
   "source": [
    "### ii) Calculate Supply Forecast for specified % Exceedance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f13f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate a specified exceedance probability (q) forecast from a series (ser)\n",
    "# Python equivalent of Excel's PERCENTILE.EXC function, which is used in Methodology spreadsheet\n",
    "def quantile_exc(ser, q):\n",
    "    ser_sorted = ser.sort_values()\n",
    "    rank = q * (len(ser) + 1) - 1\n",
    "    assert rank > 0, 'quantile is too small'\n",
    "    rank_l = int(rank)\n",
    "    # Uses Weibull plotting position formula for calculating exceedance probability\n",
    "    return float(ser_sorted.iat[rank_l] + (ser_sorted.iat[rank_l + 1] - \n",
    "                                     ser_sorted.iat[rank_l]) * (rank - rank_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e0ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_spec_excd = pd.DataFrame()\n",
    "user_spec_excd['Exceedance']=len(Trace)\n",
    "user_spec_excd['CNRFC Site'] = cnrfc_site\n",
    "\n",
    "# If a 1% Exceedance is specified, give the maximum value among the forecast traces\n",
    "if user_excd == 0.01:\n",
    "    maxValues = Trace.max(axis=1)\n",
    "    user_spec_excd['Exceedance'] = maxValues.values\n",
    "\n",
    "# If a 99% Exceedance is specified, give the minimum value among the forecast traces\n",
    "elif user_excd == 0.99:\n",
    "    minValues = Trace.min(axis=1)\n",
    "    user_spec_excd['Exceedance'] = minValues.values\n",
    "\n",
    "# For each CNRFC site, calculate a SUPPLY_PERIOD_FORECAST_CNRFC using the exceedance function\n",
    "else:\n",
    "    for x in range(len(Trace)):\n",
    "        ser = pd.Series(Trace.iloc[x], dtype=object)\n",
    "        user_spec_excd.loc[x, 'Exceedance'] = quantile_exc(ser, 1-user_excd)\n",
    "\n",
    "#display(user_spec_excd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c6f8a",
   "metadata": {},
   "source": [
    "### C. Total Supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2168f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gap-Filling Factors dataset\n",
    "gap_filling = pd.read_csv('../user-inputs/GapFillingFactors.csv')\n",
    "gap_filling = gap_filling.rename(columns={\n",
    "    f'{i:02d}_RATIO': calendar.month_abbr[i] for i in range(1, 13)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Instream Flows dataset\n",
    "instream_flow = pd.read_csv('../user-inputs/InstreamFlowsAbandoned.csv')\n",
    "instream_flow = instream_flow.rename(columns={\n",
    "    f'{i:02d}_CFS': calendar.month_abbr[i] for i in range(1, 13)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba51071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that intakes the specified Start and End Dates to calculate a multiplier\n",
    "# The multiplier is used to prorate multiple months of data down to a single value for the specified dates \n",
    "def calculate_prorated_constant(start_date, end_date, constants):\n",
    "    # Get the number of days in a month\n",
    "    def days_in_month(year, month):\n",
    "        return calendar.monthrange(year, month)[1]\n",
    "\n",
    "    # Initialize the prorated_value\n",
    "    prorated_value = 0.0\n",
    "\n",
    "    current_date = start_date\n",
    "    # Add prorated value for the start month\n",
    "    prorated_value += (days_in_month(start_date.year, start_date.month) - start_date.day + 1) / days_in_month(start_date.year, start_date.month) * constants[start_date.month - 1]\n",
    "\n",
    "    # Increment month by month until end date is reached\n",
    "    while True:\n",
    "        next_month_first_day = (current_date.replace(day=28) + timedelta(days=4)).replace(day=1) # To safely get the first day of next month\n",
    "        if next_month_first_day >= end_date:\n",
    "            break\n",
    "        \n",
    "        # Add prorated value for full month or fraction for partial month\n",
    "        if next_month_first_day.month == end_date.month:\n",
    "            prorated_value += end_date.day / days_in_month(end_date.year, end_date.month) * constants[end_date.month - 1]\n",
    "        else:\n",
    "            prorated_value += constants[next_month_first_day.month - 1]\n",
    "        current_date = next_month_first_day\n",
    "\n",
    "    # Calculate the number of days in the range\n",
    "    number_of_days = (end_date - start_date).days + 1  # plus one to include the end date\n",
    "\n",
    "    return prorated_value, number_of_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12058f96-2440-4b2a-8b83-8a243fc63c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the proration function to transform monthly Gap-Filling Factors into single Period factors based on specified Start and End Dates\n",
    "gap_list = []\n",
    "\n",
    "for gapfilling in gap_filling['GAP_FILLING_FACTOR']:\n",
    "    constant, number_of_days = calculate_prorated_constant(start_date, end_date, gap_filling.loc[gap_filling['GAP_FILLING_FACTOR'] == gapfilling].drop('GAP_FILLING_FACTOR', axis=1).squeeze())\n",
    "    gap_list.append({'Period_GAP_Constant': constant, 'GAP_FILLING_FACTOR': gapfilling})\n",
    "\n",
    "period_gap = pd.DataFrame(gap_list)\n",
    "\n",
    "#display(period_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c869be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the proration function to transform monthly Instream Flows into single Period flow volumes based on specified Start and End Dates\n",
    "inf_list = []\n",
    "\n",
    "for subwatersheds in instream_flow['SUBWATERSHED']:\n",
    "    constant, number_of_days = calculate_prorated_constant(start_date, end_date, instream_flow.loc[instream_flow['SUBWATERSHED'] == subwatersheds].drop('SUBWATERSHED', axis=1).squeeze())\n",
    "    \n",
    "    # Convert the instream flow rates (CFS) to volummes (AF)\n",
    "    inf_list.append({'INSTREAM_FLOW_PERIOD': constant*number_of_days*60*60*24/43560, 'SUBWATERSHED': subwatersheds})\n",
    "\n",
    "period_inf = pd.DataFrame(inf_list)\n",
    "\n",
    "#display(period_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export intermediate results for use in 3.Analysis script\n",
    "period_inf.to_csv('./intermediate-outputs/Instream_Flow_Period.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2e2f0",
   "metadata": {},
   "source": [
    "#### Sum Past and Forecasted Supply to calculate Supply_Period_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65680f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Supply Forecast to the specified exceedance\n",
    "supply_period_forecast_cnrfc = user_spec_excd.rename(columns = {'Exceedance':'SUPPLY_PERIOD_FORECAST_CNRFC'})\n",
    "supply_period_forecast_cnrfc = supply_period_forecast_cnrfc[['CNRFC Site', 'SUPPLY_PERIOD_FORECAST_CNRFC']]\n",
    "# The above will be zero if the End Date is in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f61305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the SUPPLY_PAST_PERIOD and SUPPLY_PERIOD_FORECAST_SELECTED values\n",
    "supply_period_total_cnrfc = pd.merge(supply_past_period, supply_period_forecast_cnrfc, on=['CNRFC Site'])\n",
    "supply_period_total_cnrfc['SUPPLY_PERIOD_TOTAL'] = supply_period_total_cnrfc['SUPPLY_PAST_PERIOD'] + supply_period_total_cnrfc['SUPPLY_PERIOD_FORECAST_CNRFC']\n",
    "\n",
    "# Zero out any negative values in 'SUPPLY_PAST_TOTAL' (negative computed unimpaired flows are summed as-is)\n",
    "supply_period_total_cnrfc.loc[supply_period_total_cnrfc['SUPPLY_PERIOD_TOTAL'] < 0, 'SUPPLY_PERIOD_TOTAL'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182883da",
   "metadata": {},
   "source": [
    "#### Assign CNRFC supply to 13 subwatersheds associated with single sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b285ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_period_total = pd.DataFrame(subwatershed, columns=['SUBWATERSHED'])\n",
    "supply_period_total['SUPPLY_PERIOD_TOTAL'] = 0\n",
    "\n",
    "# Convert 'SUPPLY_PERIOD_TOTAL' to float64 if it's not already\n",
    "supply_period_total['SUPPLY_PERIOD_TOTAL'] = supply_period_total['SUPPLY_PERIOD_TOTAL'].astype(float)\n",
    "\n",
    "# Call the dataframe created at the start to look up these 13 subwatersheds\n",
    "for x in range (13):\n",
    "    supply_period_total.loc[supply_period_total['SUBWATERSHED'] == match[x][0], 'SUPPLY_PERIOD_TOTAL'] = \\\n",
    "    supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == match[x][1], 'SUPPLY_PERIOD_TOTAL'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5004be",
   "metadata": {},
   "source": [
    "#### Calculate supply for the remaining 7 subwatersheds (sum of multiple sites, augmentation, and/or extrapolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stony is CNRFC EPRC1 augmented\n",
    "supply_period_total.loc[supply_period_total['SUBWATERSHED'] == 'Stony', 'SUPPLY_PERIOD_TOTAL'] = \\\n",
    "supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'EPRC1', 'SUPPLY_PERIOD_TOTAL'].values[0] * \\\n",
    "period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Augment_EPRC1', 'Period_GAP_Constant'].values[0]\n",
    "\n",
    "# Cache is extrapolated based on Stony\n",
    "supply_period_total.loc[supply_period_total['SUBWATERSHED'] == 'Cache', 'SUPPLY_PERIOD_TOTAL'] = \\\n",
    "supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'EPRC1', 'SUPPLY_PERIOD_TOTAL'].values[0] * \\\n",
    "period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Augment_EPRC1', 'Period_GAP_Constant'].values[0] * \\\n",
    "period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Extrapolate_Cache_Stony', 'Period_GAP_Constant'].values[0]\n",
    "\n",
    "# Bear is extrapolated based on Yuba\n",
    "supply_period_total.loc[supply_period_total['SUBWATERSHED'] == 'Bear', 'SUPPLY_PERIOD_TOTAL'] = \\\n",
    "supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'HLEC1', 'SUPPLY_PERIOD_TOTAL'].values[0] * \\\n",
    "period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Extapolate_Bear_HLEC1', 'Period_GAP_Constant'].values[0]\n",
    "\n",
    "# Putah is extrapolated based on Stony\n",
    "supply_period_total.loc[supply_period_total['SUBWATERSHED'] == 'Putah', 'SUPPLY_PERIOD_TOTAL'] = \\\n",
    "supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'EPRC1', 'SUPPLY_PERIOD_TOTAL'].values[0] * \\\n",
    "period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Augment_EPRC1', 'Period_GAP_Constant'].values[0] * \\\n",
    "period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Extrapolate_Putah_Stony', 'Period_GAP_Constant'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper Sacramento Valley is CNRFC (EDCC1+TCRC1 augmented) + (MLMC1+DCVC1+BKCC1 augmented)\n",
    "supply_period_total.loc[supply_period_total['SUBWATERSHED'] == 'Upper Sacramento Valley', 'SUPPLY_PERIOD_TOTAL'] = \\\n",
    "((supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'EDCC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'TCRC1', 'SUPPLY_PERIOD_TOTAL'].values[0]) * \\\n",
    "period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Augment_EDCC1+TCRC1', 'Period_GAP_Constant'].values[0]) + \\\n",
    "((supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'MLMC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "  supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'DCVC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "  supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'BKCC1', 'SUPPLY_PERIOD_TOTAL'].values[0]) * \\\n",
    " period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Augment_MLMC1+DCVC1+BKCC1', 'Period_GAP_Constant'].values[0])\n",
    "\n",
    "# Sacramento Valley Floor is extrapolated based on (Sacramento Bend + Upper Feather + Upper American)\n",
    "supply_period_total.loc[supply_period_total['SUBWATERSHED'] == 'Sacramento Valley Floor', 'SUPPLY_PERIOD_TOTAL'] = \\\n",
    "((supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'BDBC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "  supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'ORDC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "  supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'FOLC1', 'SUPPLY_PERIOD_TOTAL'].values[0]) * \\\n",
    "  period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Extrapolate_SacramentoValleyFloor_BDBC1+ORDC1+FOLC1', 'Period_GAP_Constant'].values[0])\n",
    "\n",
    "# San Joaquin Valley FLoor is (CNRFC MPAC1+OWCC1+MEEC1) + (extrapolated based on Upper San Joaquin + Merced + Tuolumne\n",
    "# + Stanislaus) + (extrapolated based on Mokelumne + Cosumnes)\n",
    "supply_period_total.loc[supply_period_total['SUBWATERSHED'] == 'San Joaquin Valley Floor', 'SUPPLY_PERIOD_TOTAL'] = \\\n",
    "supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'MPAC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'OWCC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'MEEC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "((supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'FRAC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "  supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'EXQC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "  supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'NDPC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "  supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'NMSC1', 'SUPPLY_PERIOD_TOTAL'].values[0]) * \\\n",
    "  period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Extrapolate_SanJoaquinValleyFloor_FRAC1+EXQC1+NDPC1+NMSC1', 'Period_GAP_Constant'].values[0]) + \\\n",
    "((supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'CMPC1', 'SUPPLY_PERIOD_TOTAL'].values[0] + \\\n",
    "  supply_period_total_cnrfc.loc[supply_period_total_cnrfc['CNRFC Site'] == 'MHBC1', 'SUPPLY_PERIOD_TOTAL'].values[0]) * \\\n",
    " period_gap.loc[period_gap['GAP_FILLING_FACTOR'] == 'Extrapolate_SanJoaquinValleyFloor_CMPC1+MHBC1', 'Period_GAP_Constant'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export intermediate results for use in 3.Analysis script\n",
    "supply_period_total.to_csv('./intermediate-outputs/Supply_Period_Total.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
